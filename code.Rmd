---
title: "Using News and Market Data to Predict Stock Movements"
course: "DATS 6101 Introduction to Data Science"
authors: "Mary Gibbs and Peter Riley"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

--------
Question
--------

Both of us are interested in the intersection of financial markets and news/social media. Initially, we wanted to model social media influence on IPO financial performance, but we were unable to obtain the data via Bloomberg Terminal. Therefore, we decided to model news influence on stock movements, utilizing data from Two Sigma.

Research Question: Can a combinaton of news and market data predict whether a company's stock will increase or decrease within a day?

----
Data  
----

We gathered a data subset from Kaggle - Two Sigma: Using News to Predict Stock Movements. Using a Kaggle Kernel and Python, we selected dates/features of interest and created a binary result column with 1 indicating a gain or stable and 0 indicating a loss. Using R, we read in the data, cleaned the data, and changed the data types. 

Data Source: https://www.kaggle.com/c/two-sigma-financial-news/data

Packages
```{r}
library(bestglm)
library(car)
library(caret)
library(caTools)
library(corrplot)
library(dplyr)
library(ggplot2)
library(ISLR)
library(MASS)
library(Metrics)
library(MLmetrics)
library(pROC)
library(pscl)
library(rattle)
library(RColorBrewer)
library(ResourceSelection)
library(rattle)
library(rpart)
library(rpart.plot)
library(ROCR)
library(tree)
library(verification)
```

Clean Data
```{r}
#read in data 
df <- read.csv("data.csv") 
#remove X column
df$X <- NULL 
#check data
str(df)
#change data types
df$binary_result <- as.factor(df$binary_result)
df$sentimentClass <- as.factor(df$sentimentClass)
df$urgency <- as.factor(df$urgency)
#check data
str(df)
```

Multicollinearity
```{r}
#correlation matrix
dfCorrMatrix <- cor(df[, c(4:7, 11:13, 15:18)], method = "pearson")
#correlation plot 
corrplot(dfCorrMatrix, method = "square", addCoef.col = "black", number.cex = 7/ncol(df))
#create df w/o highly correlated features
dfModel <- df[, c(4:5, 8:16)]
```

-----
Model
-----

We are interested in whether news characteristics/sentiment and market information can predict stock movements (gain/stable or loss). Therefore, we decided to try both logistic regression and decision tree since they are classification algorithms that are commonly used to predict binary outcomes. 

Test/Train
```{r}
#get 80% train
train <- dfModel[1:11088, ]
#get 20% test
test <- dfModel[11089:13860, ]
```

Logistic Regression
-------------------

Full Logistic Regression Model 
```{r}
#full model 
fullModel <- glm(binary_result ~ volume + open + provider + sentimentClass + sentimentNegative + sentimentNeutral + sentimentPositive + urgency + firstMentionSentence + bodySize, family = binomial(link = "logit"), data = train)

#full model summary
summary(fullModel)
#volume and open are statistically significant (p-value < 0.05), contribute to model
#null deviance is 15345 and residual deviance is 15233, terrible reduction
#AIC is 15281

#full model VIF
vif(fullModel)
#VIF < 5, no multicollinearity issues
```

Stepwise Logistic Regression Model
```{r}
#stepwise model
stepModel <- fullModel %>% stepAIC(trace = TRUE)

#stepwise model summary
summary(stepModel)
#open and volume are statistically significant (p-value < 0.05), contribute to model
#null deviance is 15345 and residual deviance is 15237, terrible reduction
#AIC is 15271, better than full model

#stepwise model VIF
vif(stepModel)
#VIF < 5, no multicollinearity issues
```

Stepwise Logistic Regression Model Prediction
```{r}
#stepwise model predicition
stepModelPrediction <- predict(stepModel, newdata = test, type = "response")
```

Stepwise Logistic Regression Model Accuracy
```{r}
#stepwise model accuracy
stepModelPerLike <- ifelse(stepModelPrediction > 0.5, 1, 0)
stepModelAccuracy <- mean(stepModelPerLike == test$binary_result)
stepModelAccuracy
#stepwise model accuracy is 47.40%, terrible
```

Stepwise Logistic Regression Model ROC Curve
```{r}
#stepwise model ROC curve
stepModelROCpred <- prediction(stepModelPrediction, test$binary_result)
stepModelROCperf <- performance(stepModelROCpred, measure = "tpr", x.measure = "fpr")
plot(stepModelROCperf, xlab = "false positive rate", ylab = "true positive rate")
#stepwise model ROC curve is terrible

#stepwise model AUC
stepModelAUC <- performance(stepModelROCpred, measure = "auc")
stepModelAUC
#stepwise model AUC is 0.4922, terrible
```

Decision Tree
-------------

Decision Tree
```{r}
#decision tree
set.seed(1)
tree <- rpart(binary_result ~ volume + open + provider + sentimentClass + sentimentNegative + sentimentNeutral + sentimentPositive + urgency + firstMentionSentence + bodySize, data = train, control = rpart.control(maxdepth = 6), method = "class")

#decision tree results
View(tree$cptable)
summary(tree)
#open and volume are important variables

#decision tree visualization
png("tree.png", width = 1000, height = 600)
post(tree, file = "", title = "Decision Tree")
dev.off()
```

Decision Tree Prediction
```{r}
#decision tree prediction
treePrediction <- predict(tree, newdata = test, type = "class")
#open and volume are important variables
```

Decision Tree Accuracy
```{r}
#decision tree true positive and true negative 
treePredictionTable <- table(test$binary_result, treePrediction) 
treePredictionTable

#decision tree confusion matrix
confusionMatrix(treePrediction, test$binary_result)
#decision tree accuracy is 49.06%, terrible
```

-------------------
Predictions/Results
-------------------

For both models, the market variables open and volume were important, while the news variables were insignificant. The decision tree accuracy (49.06%) was greater than the logistic regression accuracy (47.40%). However, for both models, accuracy was less than 50%, making randomly guessing an almost equivalent option. Ultimately, the news characteristics/sentiment and the market information were terrible predictors of stock movements.
